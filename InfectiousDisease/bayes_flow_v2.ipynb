{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "# Data\n",
    "from data.data_generator import data_generator\n",
    "from data.data_generator import data_model\n",
    "from data.data_filtering import (sanity_checks, est_sanity_checks, sample_sanity_checks)\n",
    "\n",
    "# Model\n",
    "from models.models import HeteroskedasticModel\n",
    "from models.models import BayesFlow\n",
    "\n",
    "# Utils\n",
    "from utils.losses import heteroskedastic_loss, maximum_likelihood_loss\n",
    "from utils.training import train_step\n",
    "from utils.viz import (plot_true_est_scatter, plot_true_est_posterior, \n",
    "                       plot_correlation_parameters, plot_comp_post_prior, plot_ppc)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Heteroskedastic model as summary net\n",
    "class SummaryNet(tf.keras.Model):\n",
    "    def __init__(self, meta):\n",
    "        super(CustomSummaryNetwork, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the summary network\n",
    "        Arguments:\n",
    "        x : tf.Tensor of shape (batch_size, n_obs, x_dim) - a batch of samples from p(x|params)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Do something with input\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-enlargement",
   "metadata": {},
   "source": [
    "### Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network hyperparameters\n",
    "inv_meta = {\n",
    "    'n_units': [64, 64, 64],\n",
    "    'activation': 'elu',\n",
    "    'w_decay': 0.0,\n",
    "    'initializer': 'glorot_uniform'\n",
    "}\n",
    "n_inv_blocks = 5\n",
    "\n",
    "# Optional if using the predefined summary nets\n",
    "summary_meta = {\n",
    "    'n_units': [192, 192, 192],\n",
    "    'activation': 'elu',\n",
    "    'w_decay': 0.0,\n",
    "    'initializer': 'glorot_uniform'\n",
    "}\n",
    "\n",
    "\n",
    "# Forward model hyperparameters\n",
    "parameter_names = [r'$\\beta$', r'$\\alpha$', r'$\\gamma$', r'$\\delta$', r'$\\eta$']\n",
    "theta_dim = len(parameter_names)\n",
    "n_test = 500\n",
    "\n",
    "\n",
    "# Training and optimizer hyperparameters\n",
    "ckpt_file = \"SEIDR_v2\"\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "iterations_per_epoch = 1000\n",
    "n_samples_posterior = 2000\n",
    "\n",
    "starter_learning_rate = 0.001\n",
    "global_step = tf.Variable(0, dtype=tf.int32)\n",
    "decay_steps = 1000\n",
    "decay_rate = .95\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(starter_learning_rate, decay_steps, decay_rate)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-houston",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_test = data_generator(n_test)\n",
    "\n",
    "# Preprocessing untrained data\n",
    "x_test = np.array(data_test['x'])\n",
    "theta_test = np.array(data_test['theta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-values",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(x_test))\n",
    "print(x_test.shape)\n",
    "print(type(theta_test))\n",
    "print(theta_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "x_test, theta_test = sanity_checks(x_test, theta_test)\n",
    "\n",
    "# Sanity checks for numerical stability\n",
    "assert(np.sum(x_test == np.inf) == 0)\n",
    "assert(np.sum(x_test == -np.inf) == 0)\n",
    "assert(np.sum(x_test == np.nan) == 0)\n",
    "\n",
    "# Reshape x\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(theta_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-clause",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "summary_net = HeteroskedasticModel(summary_meta)\n",
    "model = BayesFlow(inv_meta, n_inv_blocks, theta_dim, summary_net=summary_net, permute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-african",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_est_scatter(model, x_test, theta_test, n_samples_posterior, parameter_names, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-equilibrium",
   "metadata": {},
   "source": [
    "### Manage checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(step=global_step, optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, './checkpoints/{}'.format(ckpt_file), max_to_keep=3)\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-tourist",
   "metadata": {},
   "source": [
    "### Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-companion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "for ep in range(1, epochs + 1):\n",
    "    with tqdm(total=iterations_per_epoch, desc='Training epoch {}'.format(ep)) as p_bar:\n",
    "        losses = train_step(model=model, \n",
    "                            optimizer=optimizer,\n",
    "                            loss_fn=maximum_likelihood_loss, \n",
    "                            iterations=iterations_per_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            p_bar=p_bar,\n",
    "                            global_step=global_step) \n",
    "\n",
    "        # Manage checkpoint\n",
    "        manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-portable",
   "metadata": {},
   "source": [
    "### Posterior means & Full posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation sanity checks\n",
    "theta_samples = model.sample(x_test, n_samples_posterior, to_numpy=True)\n",
    "theta_approx_means = theta_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftheta_approx_means, ftheta_test, fx_test = est_sanity_checks(theta_approx_means, theta_test, x_test=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fx_test.shape)\n",
    "print(ftheta_test.shape)\n",
    "print(ftheta_approx_means.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_est_scatter(model, fx_test, ftheta_test, n_samples_posterior, parameter_names, figsize=(12, 3), theta_approx_means=ftheta_approx_means)\n",
    "\n",
    "plot_true_est_posterior(model, 2000, parameter_names, font_size=8,\n",
    "                        X_test=fx_test[:5], \n",
    "                        theta_test=ftheta_test[:5], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-helping",
   "metadata": {},
   "source": [
    "What we have up to this point:\n",
    "- x_test: array-like of shape (500, 500) -- 500 time series for 5 compartiments\n",
    "- theta_samples: array-like of shape (n_samples_posterior, 500, 5) -- n_samples_posterior of tuples of parameter theta for the 500 time series. That is, for each time series of 5 compartiments, each sample of the n_samples_posterior will consist of 500 plausible tupples of parameters (each tuple consists of 5 parameters)\n",
    "\n",
    "ToDo:\n",
    "\n",
    "Iterate through all time series and exclude those parameters that are impossible (est sanity checks)\n",
    "So, when iterating through all time series, an array-like of shape (n_samples_posterior, 1, 5) --> (n_samples_posterior, 5) is obtained. The posteriors are then compared with the ground truth estimations.\n",
    "\n",
    "This array is filtered and used for resimulation\n",
    "\n",
    "Resimulation: The time series are computed by passing the obtained and filtered array of tuples.\n",
    "A total of fn_samples_posterior time series are simulated and compared with the posterior predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random time series\n",
    "sel_idx = np.random.choice(theta_samples.shape[1], 1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_theta_samples = theta_samples[:, sel_idx, :].squeeze()\n",
    "sel_theta_test = theta_test[sel_idx, :].squeeze()\n",
    "sel_x_test = x_test[sel_idx, :].squeeze().reshape(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "fsel_theta_samples = sample_sanity_checks(sel_theta_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-modem",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sel_x_test.shape)\n",
    "print(sel_theta_test.shape)\n",
    "print(fsel_theta_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-trauma",
   "metadata": {},
   "source": [
    "### Correlation of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-princeton",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(parameter_names)\n",
    "plot_correlation_parameters(fsel_theta_samples, parameter_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-service",
   "metadata": {},
   "source": [
    "### Ground-Truth comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-Truth comparison\n",
    "# For each parameter compute NRMSE\n",
    "nrmses = []\n",
    "for i in range(5):\n",
    "    # Compute NRMSE\n",
    "    rmse = np.sqrt(np.mean((fsel_theta_samples[:, i] - sel_theta_test[i]) ** 2))\n",
    "    nrmse = rmse / (sel_theta_test[i])\n",
    "    nrmses.append(nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ground-truth comparison (normalized root-mean-square deviation): \\n{}\".format(nrmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel_theta_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resimulation\n",
    "t_obs = 100\n",
    "dt = 1\n",
    "t = np.linspace(0, t_obs, int(t_obs/dt))\n",
    "N = 10000\n",
    "init_vals = 1 - 1/N, 1/N, 0, 0, 0\n",
    "forward_model = partial(data_model, initial_values=init_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.empty((fsel_theta_samples.shape[0], t_obs, 5))\n",
    "for i in range(fsel_theta_samples.shape[0]):\n",
    "    ts[i, :, :] = forward_model(fsel_theta_samples[i, :], t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['S', 'E', 'I', 'R', 'D']\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series\n",
    "plt.rcParams['font.size'] = 11\n",
    "f, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "for i in range(5):\n",
    "    ax.plot(ts[0, :, i], label=labels[i], lw=2)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-intro",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot posterior predictive comparison of n random samples\n",
    "cmap = cm.Blues\n",
    "plot_ppc(t, ts, labels, sel_x_test, ps=True, cmedian='Blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}